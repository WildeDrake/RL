[training]
#----------------------------------------- Configuración del entorno -----------------------------------------#
# El entorno de OpenAI Gym en el que se entrenará el agente DQN.
env = ALE/Frogger-v5      
#----------------------------------------- Configuración del Agente -----------------------------------------#
# El tipo de agente de aprendizaje por refuerzo que se utilizará para entrenar en el entorno.
agent = DQN               
# La ruta del archivo donde se guardará el modelo entrenado.
model_path = ./models/RainbowDQNModel.pth   
# El nombre de la run de entrenamiento, utilizado para organizar los resultados.
run_name = RainbowDQNAgent
#----------------------------------------- Configuración del entrenamiento -----------------------------------------#
# El número de episodios de entrenamiento que se deben completar antes de guardar el modelo entrenado en disco.
save_model_interval = 500  
# El número total de episodios de entrenamiento que se deben ejecutar. 
episodes = 10_000           
# La longitud máxima de cada episodio de entrenamiento en pasos. Si un episodio alcanza esta longitud, se termina automáticamente.
max_episode_length = 2_000
#----------------------------------------- Configuración del agente DQN -----------------------------------------#
# El valor inicial de la tasa de exploracion del agente.
eps_start = 1.0         
# El valor minimo de la tasa de exploracion del agente.
eps_end = 0.01          
# El número de pasos de entrenamiento que se deben realizar antes de que la tasa de exploracion del agente disminuya a su valor minimo.
eps_decay = 8_000
# La tasa de aprendizaje del optimizador utilizado para entrenar la red neuronal del agente. Controla qué tan rápido se
# ajustan los pesos del modelo durante el entrenamiento.
learning_rate = 0.0001  
# El factor de descuento utilizado para calcular los objetivos de Q-valor objetivo del agente. 
# Controla la importancia relativa de las recompensas futuras frente a las recompensas inmediatas.
gamma = 0.99
# El número de pasos de entrenamiento que se deben realizar antes de que la red neuronal del agente se actualicen con los pesos de la
# la red neuronal del agente. Esto controla con qué frecuencia se actualiza la red neuronal objetivo.
target_update = 1_500
# El número de transiciones de experiencia que se deben almacenar en la memoria de repeticion antes de que el
# agente comience a entrenar. Esto permite que el agente acumule un conjunto de experiencias inicial antes de 
# comenzar a entrenar.
initial_memory = 20_000
# El tamaño de la memoria de repeticion utilizada para almacenar las transiciones de experiencia del agente. 
# El agente entrena en muestras de experiencia muestreadas aleatoriamente de la memoria de repeticion.
memory_size = 200_000
# El número de muestras de experiencia que se deben muestrear de la memoria de repeticion para cada paso de entrenamiento.
# Esto controla el número de muestras de experiencia que se utilizan para calcular la pérdida de entrenamiento en cada paso de entrenamiento.
batch_size = 128
#----------------------------------------- Configuración del agente Rainbow DQN -----------------------------------------#
# Habilitar Double DQN
use_double = True
# Habilitar Dueling DQN
use_dueling = True
# Habilitar Prioritized Experience Replay
use_per = True
# Habilitar Multi-step Learning (N-step)
use_multi_step = True
# Habilitar Noisy Nets
use_noisy = True
# Habilitar Distributional RL (C51)
use_distributional = True


[testing]
#----------------------------------------- Configuración del entorno -----------------------------------------#
# El entorno de OpenAI Gym en el que se probará el agente DQN.
env = ALE/Frogger-v5
#----------------------------------------- Configuración del entrenamiento -----------------------------------------#
# La longitud máxima de cada episodio de prueba en pasos. Si un episodio alcanza esta longitud, se termina automáticamente.
max_steps_per_episode = 2000   
#----------------------------------------- Configuración de output -----------------------------------------#
# El número total de episodios de prueba que se deben ejecutar.
episodes = 3                       
# La carpeta donde se guardarán los videos de las ejecuciones de prueba del agente.
video_folder = ./videos/RainbowDQNModel/   
#----------------------------------------- Configuración del Agente -----------------------------------------#
# El tipo de agente de aprendizaje por refuerzo que se utilizará para entrenar en el entorno.
agent = DQN               
# La ruta del archivo donde se encuentra el modelo entrenado que se utilizará para las pruebas.
model_path = ./models/RainbowDQNModel.pth