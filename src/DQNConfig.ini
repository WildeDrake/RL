[Training]
'''----------------------------------------- Configuración del entorno -----------------------------------------'''
env = ALE/Frogger-v5    # El entorno de OpenAI Gym en el que se entrenará el agente DQN.
actions = 5             # El número de acciones posibles que el agente puede tomar en el entorno.
'''----------------------------------------- Configuración del Agente -----------------------------------------'''
agent = DQN               # El tipo de agente de aprendizaje por refuerzo que se utilizará para entrenar en el entorno.
model_path = DQNModel.pth   # La ruta del archivo donde se guardará el modelo entrenado.
'''----------------------------------------- Configuración del entrenamiento -----------------------------------------'''
episodes = 10_000           # El número total de episodios de entrenamiento que se deben ejecutar.
max_episode_length = 2000   # La longitud máxima de cada episodio de entrenamiento en pasos. Si un episodio alcanza esta longitud, 
                            # se termina automáticamente.
save_model_interval = 250   # El número de episodios de entrenamiento que se deben completar antes de guardar el modelo entrenado en disco.
'''----------------------------------------- Configuración del agente DQN -----------------------------------------'''
eps_start = 1.0         # El valor inicial de la tasa de exploracion del agente.
eps_end = 0.01          # El valor minimo de la tasa de exploracion del agente.
eps_decay = 9_000       # El número de pasos de entrenamiento que se deben realizar antes de que la tasa de exploracion del 
                        # agente alcance su valor minimo.
memory_size = 20_000    # Tamaño de la memoria de repeticion utilizada para almacenar las transiciones de experiencia del agente. 
                        # El agente entrena en muestras de experiencia muestreadas aleatoriamente de la memoria de repeticion.
learning_rate = 0.0002  # La tasa de aprendizaje del optimizador utilizado para entrenar la red neuronal del agente. Controla qué tan rápido 
                        # se ajustan los pesos del modelo durante el entrenamiento.
initial_memory = 10_000 # El número de transiciones de experiencia que se deben almacenar en la memoria de repeticion antes de que el 
                        # agente comience a entrenar. Esto permite que el agente acumule un conjunto de experiencias inicial antes de 
                        # comenzar a entrenar.
gamma = 0.99            # El factor de descuento utilizado para calcular los objetivos de Q-valor objetivo del agente. 
                        # Controla la importancia relativa de las recompensas futuras frente a las recompensas inmediatas.
target_update = 1_500   # El número de pasos de entrenamiento que se deben realizar antes de que los pesos de la red neuronal 
                        # objetivo se actualicen con los pesos de la red neuronal del agente. Esto controla con qué frecuencia se actualiza 
                        # la red neuronal objetivo.
batch_size = 32         # El número de muestras de experiencia que se deben muestrear de la memoria de repeticion para cada 
                        # paso de entrenamiento. Esto controla el número de muestras de experiencia que se utilizan para calcular 
                        # la pérdida de entrenamiento en cada paso de entrenamiento.



[Testing]
'''----------------------------------------- Configuración del entorno -----------------------------------------'''
env = ALE/Frogger-v5    # El entorno de OpenAI Gym en el que se probará el agente DQN.
actions = 5             # El número de acciones posibles que el agente puede tomar en el entorno.
'''----------------------------------------- Configuración del entrenamiento -----------------------------------------'''
max_steps_per_episode = 2000   # La longitud máxima de cada episodio de prueba en pasos. Si un episodio alcanza esta longitud, se termina automáticamente.
'''----------------------------------------- Configuración de output -----------------------------------------'''
episodes = 10                       # El número total de episodios de prueba que se deben ejecutar.
video_folder = ./videos/DQNModel/   # La carpeta donde se guardarán los videos de las ejecuciones de prueba del agente.
'''----------------------------------------- Configuración del Agente -----------------------------------------'''
agent = DQN               # El tipo de agente de aprendizaje por refuerzo que se utilizará para entrenar en el entorno.
model_path = ./models/DQNAgent/in_progress_model_6000.pth   # La ruta del archivo donde se encuentra el modelo entrenado que se utilizará para las pruebas.